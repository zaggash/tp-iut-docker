<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Home on Docker et Orchestration</title><link>https://zaggash.github.io/tp-iut-docker/</link><description>Recent content in Home on Docker et Orchestration</description><generator>Hugo -- gohugo.io</generator><language>fr-fr</language><lastBuildDate>Mon, 08 Jun 2020 23:48:04 +0200</lastBuildDate><atom:link href="https://zaggash.github.io/tp-iut-docker/index.xml" rel="self" type="application/rss+xml"/><item><title>Créer son cluster Swarm</title><link>https://zaggash.github.io/tp-iut-docker/orchestration/swarm/create_swarm/</link><pubDate>Mon, 15 Jun 2020 21:37:57 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/orchestration/swarm/create_swarm/</guid><description>Activation Swarm n&amp;rsquo;est pas actif par defaut dans Docker.
Essayer la commande suivante:
$ docker node ls Le premier noeud d&amp;rsquo;un cluster Swarm est initialisé avec docker swarm init
Ne pas executer docker swarm init sur tous les noeuds !
Vous auriez plusieurs clusters différents.
Pour commencer il faut bien nommer ses machines.
Vérifier que les VMs ont bien 3 noms distincts, sinon renommer les !
$ sudo hostnamectl set-hostname node1 $ sudo hostnamectl set-hostname node2 $ sudo hostnamectl set-hostname node3 Puis vérifier qu&amp;rsquo;ils sont bien synchronisé à un serveur de temps</description></item><item><title>Installer docker-compose</title><link>https://zaggash.github.io/tp-iut-docker/orchestration/install-compose/</link><pubDate>Sun, 14 Jun 2020 18:08:25 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/orchestration/install-compose/</guid><description>Bien que nous puissions installer Docker Compose à partir des repos officiels Ubuntu, cette version n&amp;rsquo;est pas très à jour.
Nous allons donc installer Docker Compose à partir du repo github de Docker Compose .
Le site de Docker propose une documentation pour l&amp;#39;installation .
$ latest=$(curl -sL &amp;#34;https://api.github.com/repos/docker/compose/releases/latest&amp;#34; |\jq -r &amp;#39;.tag_name&amp;#39;) $ sudo curl -L &amp;#34;https://github.com/docker/compose/releases/download/$latest/docker-compose-$(uname -s)-$(uname -m)&amp;#34; -o /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose $ docker-compose --version</description></item><item><title>Les Namespaces</title><link>https://zaggash.github.io/tp-iut-docker/docker_linux/namespaces/</link><pubDate>Sun, 14 Jun 2020 11:39:32 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/docker_linux/namespaces/</guid><description>Les Namespaces jouent un rôle important dans les conteneurs.
Ils permettent de placer les conteneurs dans leur propre vu du système et limitent ce que l&amp;rsquo;on peut faire et voir.
Il y a different type de namespaces:
pid net mnt uts ipc user Les namespaces font partie du Kernel et sont actifs dès le démarrage de l&amp;rsquo;OS.
Même sans l&amp;rsquo;utilisation des conteneurs, il y a au moins un namespace de chaque type qui contient tous les processus du système.</description></item><item><title>Le Dockerfile</title><link>https://zaggash.github.io/tp-iut-docker/image_automation/dockerfile/</link><pubDate>Fri, 12 Jun 2020 23:23:40 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/image_automation/dockerfile/</guid><description>Un Quoi ? Le dockerfile est en gros la recette pour créer une image Docker.
Il contient toutes les instructions pour indiquer au daemon quoi faire et comment doit être construite notre image.
La commande à utiliser est docker build
Notre premier Dockerfile Vous pouvez utiliser la commande suivante pour nettoyer votre environnement docker du travail précédent.
docker rm -f $(docker ps -q); docker system prune -af --volumes
Ces commandes suppriment les conteneurs actifs puis les volumes/images/conteneurs inactifs</description></item><item><title>Les Pilotes Réseau</title><link>https://zaggash.github.io/tp-iut-docker/docker_linux/networks/network_driver/</link><pubDate>Fri, 12 Jun 2020 23:23:40 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/docker_linux/networks/network_driver/</guid><description>Docker inclut plusieurs drivers Réseau que l&amp;rsquo;on peut choisir avec l&amp;rsquo;option --net &amp;lt;driver&amp;gt;
bridge (par defaut) none host container Le bridge Par defaut le conteneur obtient une interface virtuelle eth0 en plus de son interface de bouclage (127.0.0.1)
Cette interface est fournie par une paire de veth.
Elle est connectée au Bridge Docker appelé docker0 par defaut.
Les adresses sont allouées dans un réseau privé interne 172.17.0.0/16 par défault.
Le trafic sortant passe par une régle iptables MASQUERADE, puis le trafic entrant et naté par DNAT.</description></item><item><title>Image vs Conteneur</title><link>https://zaggash.github.io/tp-iut-docker/docker/work_with_images/image_vs_container/</link><pubDate>Thu, 11 Jun 2020 23:10:12 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/docker/work_with_images/image_vs_container/</guid><description>Une image n&amp;rsquo;est pas un conteneur ! Une image est un système de fichiers en lecture seule
Un conteneur est processus qui s&amp;rsquo;execute dans une copie de ce système de fichiers.
Pour accélérer le démarrage et optimiser les accès disque, plutôt que de copier l&amp;rsquo;image entière, on utilise ici du Copy-On-Write.
Plusieurs conteneurs peuvent donc utiliser la même image sans dupliquer les données.
Si une image est en lecture seule, on ne modifie pas une image, on en crée une nouvelle.</description></item><item><title>Créer un service</title><link>https://zaggash.github.io/tp-iut-docker/orchestration/swarm/create_service/</link><pubDate>Mon, 15 Jun 2020 21:37:57 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/orchestration/swarm/create_service/</guid><description>Pour les besoins du TP, on va garder un manager et 2 workers.
Les applications ne sont pas critiques et nous sommes en mode POC.
On va donc ne garder que node1 en tant que manager.
Executer la commande suivante sur node1 :
$ docker node demote node2
$ docker node demote node3
Lancer le service On lance un service avec la commande docker service create ..., on peut faire l&amp;rsquo;analogie avec docker run .</description></item><item><title>Une app Docker Compose</title><link>https://zaggash.github.io/tp-iut-docker/orchestration/compose-app/</link><pubDate>Sun, 14 Jun 2020 22:12:23 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/orchestration/compose-app/</guid><description>Docker fournit un repository Github avec plusieurs applications pour tester Docker.
Nous allons utiliser l&amp;rsquo;application dockercoins pour essayer Docker Compose.
J&amp;rsquo;ai préparé l&amp;rsquo;application dans le repo du TP.
Vous pouvez récupérer le repo sur la machine en clonant le repo git du TP.
$ git clone https://github.com/zaggash/tp-iut-docker.git $ cd tp-iut-docker/ $ cd dockercoins/ On ne va pas rentrer dans trop de details concernant la syntaxe d&amp;rsquo;un docker-compose.yaml.
Cela prendrait beaucoup de temps et la documentation de Docker est un bien meilleur référentiel avec un tas d&amp;rsquo;exemples et d&amp;rsquo;explications.</description></item><item><title>Dans le Réseau</title><link>https://zaggash.github.io/tp-iut-docker/docker_linux/networks/inside_network/</link><pubDate>Fri, 12 Jun 2020 23:23:40 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/docker_linux/networks/inside_network/</guid><description>On peut lister les réseaux avec docker network ls
$ docker network ls NETWORK ID NAME DRIVER SCOPE a5fa804dcca5 bridge bridge local a5a200b4762b host host local b35f65ab844b none null local On peut considérer un réseau comme un Virtual Switch.
Docker va lui assigner automatiquement un sous-réseau puis une IP aux conteneurs associés.
Les conteneurs peuvent faire partis de plusieurs réseaux à la fois.
Les noms des conteneurs sont résolus via un serveur DNS embarqué dans le Docker daemon.</description></item><item><title>Le Docker Hub</title><link>https://zaggash.github.io/tp-iut-docker/image_automation/dockerhub/</link><pubDate>Fri, 12 Jun 2020 23:23:40 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/image_automation/dockerhub/</guid><description>Le Nommage Les images docker doivent respecter un certain schema de nommage pour être partager dans un registry.
Il y a 3 espaces de noms:
Les images officielles
alpine, ubuntu, python Les images officielles sont selectionées par Docker.
Elles sont directement dans l&amp;rsquo;espace de nom racine.
Ce sont généralement des images de tiers reconnues.
https://hub.docker.com Les images d&amp;rsquo;utilisateurs (ou d&amp;rsquo;organisations)
ghcr.io/zaggash/random L&amp;rsquo;espace de nom utilisateur contient les images des utilisateurs ou organisations.</description></item><item><title>Conteneurs en arrière-plan</title><link>https://zaggash.github.io/tp-iut-docker/docker/work_with_container/background/</link><pubDate>Thu, 11 Jun 2020 23:10:12 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/docker/work_with_container/background/</guid><description>Un conteneur non-interactif Nous allons lancer un conteneur tout simple qui affiche des nombres aléatoires chaque seconde.
$ docker run ghcr.io/zaggash/random 23008 19194 17802 16235 8189 667 Ce conteneur continuera de s&amp;rsquo;executer indéfiniement. Un ctrl+c permet de l&amp;rsquo;arrêter. en arrière-plan Nous pouvons lancer ce conteneur de la meme manière mais en arrière plan avec l&amp;rsquo;option -d
$ docker run -d ghcr.io/zaggash/random a5a20f1f8897d6b7a7644a322141ad74a3c21e28530b11cf10ef583ba539e55c On ne voit plus la sortie standard du conteneur, mais le daemon dockerd collecte toujours stdin/stdout du conteneur et les écrit dans un fichier de log.</description></item><item><title>Création Image Interactive</title><link>https://zaggash.github.io/tp-iut-docker/docker/work_with_images/interactive_image/</link><pubDate>Thu, 11 Jun 2020 23:10:12 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/docker/work_with_images/interactive_image/</guid><description>Créer une image à partir d&amp;rsquo;un conteneur Il est possible de créer une image partir d&amp;rsquo;un conteneur et de ses modifications.
Meme si cette solution n&amp;rsquo;est pas la plus utilisée, elle peut être utilsée à des fins de tests ou de sauvegarde.
Reprenons notre exemple avec figlet pour créer une nouvelle image à partir du conteneur. Pour cela nous allons:
Lancer un conteneur avec une image de base de votre choix.</description></item><item><title>Docker Engine</title><link>https://zaggash.github.io/tp-iut-docker/introduction/architecture/internal_architecture/</link><pubDate>Tue, 09 Jun 2020 02:38:40 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/introduction/architecture/internal_architecture/</guid><description>Le Docker Engine est divisé en plusieurs parties.
dockerd (REST API, authentification, réseaux, stockage) : Fait appel à containerd containerd (Gère la vie des conteneurs, push/pull les images) runc (Lance l&amp;rsquo;application du conteneur) containerd-shim (Par conteneur; permet de separer le processus et RunC) Plusieurs fonctionnalitées sont progressivement deleguées du Docker Engine à containerd
Des exercices du TP permettrons de verifier cela après l&amp;rsquo;installation</description></item><item><title>Deploiements complexes</title><link>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/complex_deployments/</link><pubDate>Mon, 08 Jun 2020 23:09:18 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/complex_deployments/</guid><description>
Les deploiements deviennent de plus en plus compliqués, voici quelques exemples.
De nombreuses couches applicatives:
Language (php, go, JS,&amp;hellip;) Framework Bases de données Plusieurs environnements cibles:
Machines locales pour les tests Environnements de Dev, QA, Pre-Prod, Prod Serveurs locaux, Cloud</description></item><item><title>Le réseau Ingress Overlay</title><link>https://zaggash.github.io/tp-iut-docker/orchestration/swarm/ingress_overlay/</link><pubDate>Mon, 15 Jun 2020 21:37:57 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/orchestration/swarm/ingress_overlay/</guid><description>Pour commencer cette partie, nous allons supprimer le service demo
docker service rm demo
Swarm et les Overlay Nous venons de déployer une application sur le cluster et l&amp;rsquo;on a vu que le port du service est disponible sur tous les noeuds.
Cela est possible grâce au réseau par défaut de Swarm, appelé ingress.
$ docker network ls NETWORK ID NAME DRIVER SCOPE 6b141a0943ca bridge bridge local bfc621566968 docker_gwbridge bridge local 6dbb4bea0e35 host host local 1b6ek4sxqg9g ingress overlay swarm 797221e77f12 none null local C&amp;rsquo;est un réseau overlay installé de base, et nécessaire pour les flux entrant.</description></item><item><title>[Optionel] Github</title><link>https://zaggash.github.io/tp-iut-docker/image_automation/github/</link><pubDate>Fri, 12 Jun 2020 23:23:40 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/image_automation/github/</guid><description>Pour aller plus loin&amp;hellip; Si vous le sentez, vous pouvez créer un repo sur Gihub pour pousser votre Dockerfile créé précédemment.
Puis configurer un build automatique de votre Dockerfile grâce au DockerHub.</description></item><item><title>Les Volumes</title><link>https://zaggash.github.io/tp-iut-docker/docker_linux/volumes/</link><pubDate>Fri, 12 Jun 2020 23:23:40 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/docker_linux/volumes/</guid><description>Les volumes permettent plusieurs choses:
Passer outre le Copy On Write et utiliser les performances natives des disques. Partager des dossiers et fichiers entre les conteneurs Partager des dossiers et fichiers entre l&amp;rsquo;hôte et les conteneurs Utiliser des points de montage distant Nous allons voir comment utiliser un volume:
Dans un Dockerfile Au demarrage avec l&amp;rsquo;option -v En utilisant un volume nommé La persistance des données Illustrons l&amp;rsquo;état par défaut des données après l&amp;rsquo;arrêt d&amp;rsquo;un conteneur</description></item><item><title>Copy-On-Write</title><link>https://zaggash.github.io/tp-iut-docker/docker/copy_on_write/</link><pubDate>Thu, 11 Jun 2020 23:10:12 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/docker/copy_on_write/</guid><description>Le copy-on-write Le copy-on-write ( CoW ) permet de partager les layers des images entre les conteneurs.
Dès que le conteneur à besoin d&amp;rsquo;ecrire dans un fichier existant dans une image, celui-ci est copié dans le layer en écriture du conteneur puis modifié.
On retrouve ce principe dans les snapshots BTRFS, le provisioning VMwawre,&amp;hellip;
Grâce à cela, le demarrage des conteneurs est rapide, pas besoin de copier l&amp;rsquo;image.
Le système de fichier CoW recommandé et supporté par docker est Overlay2</description></item><item><title>Installer Docker</title><link>https://zaggash.github.io/tp-iut-docker/introduction/install_docker/</link><pubDate>Thu, 11 Jun 2020 21:09:18 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/introduction/install_docker/</guid><description>Dans cette partie, nous allons prendre la main sur les VMs et installer Docker qui nous servira tout au long de la suite du TP.
Connection à la VM Dans un premier temps, se connecter en SSH à la VM.
Afin de préparer l&amp;rsquo;environnement pour la suite, l&amp;rsquo;installation devra se faire sur les 3 VMs.
ssh [-i private_key] user@hostname Mettre à jour l&amp;rsquo;OS Afin d&amp;rsquo;être dans les meilleurs conditions possible et que nos machines soient identiques, commençons par mettre à jour les VMs.</description></item><item><title>Namespaces/Cgroups/CoW</title><link>https://zaggash.github.io/tp-iut-docker/introduction/architecture/namespaces_cgroups/</link><pubDate>Tue, 09 Jun 2020 03:02:54 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/introduction/architecture/namespaces_cgroups/</guid><description>Docker est extrémement lié au Kernel.
Le fonctionnement des conteneurs repose sur les namespaces, les cgroups et le CopyOnWrite.
Mais egalement d&amp;rsquo;autres aspects liés à la sécurité comme les CAPabilities, seccomp,&amp;hellip;
Ceux qui nous intéressent aujourd&amp;rsquo;hui sont les trois premiers : namespaces, cgroups et le CopyOnWrite.
Ces aspects seront abordés au cours des exercices du TP.
Brièvement, les namespaces permettent l&amp;rsquo;isolation des processus à différent niveaux (PID, User, Network, Mount)</description></item><item><title>Deploiements simplifiés</title><link>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/easier_deployments/</link><pubDate>Mon, 08 Jun 2020 23:09:18 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/easier_deployments/</guid><description>Une application construite dans une image peut tourner n&amp;rsquo;importe où.
Cela simplifie la chaine de deploiement et assure que l&amp;rsquo;application soit la même partout où elle s&amp;rsquo;execute.
Un conteneur retire les problématiques de dépendances, de différences de paquets entre les OS, de configurations qui différent.
On oublie le fameux: &amp;ldquo;Moi, ca marche sur ma machine&amp;hellip;&amp;rdquo;</description></item><item><title>Les Stacks</title><link>https://zaggash.github.io/tp-iut-docker/orchestration/stacks/</link><pubDate>Mon, 15 Jun 2020 21:37:57 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/orchestration/stacks/</guid><description>docker-compose est bien pour le développement en locale.
Il existe plusieurs versions de compose-file : https://docs.docker.com/compose/compose-file/ A partir de la version 3, les compose-file.yaml peuvent être utilisé pour les déploiements dans Swarm.
On déploie un compose-file dans swarm avec la commande docker stack deploy -c &amp;lt;mon_compose.yaml&amp;gt; &amp;lt;nom_de_ma_stack&amp;gt;
Dans cette version de compose, une section deploy est intégré est permet de configurer les déploiements.
Une stack simple. En mode service sans la stack, on l&amp;rsquo;aurait déployé comme ceci docker service create --publish 1234:80 ghcr.</description></item><item><title>Retour sur notre Application</title><link>https://zaggash.github.io/tp-iut-docker/orchestration/swarm/multi_services_app/</link><pubDate>Mon, 15 Jun 2020 21:37:57 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/orchestration/swarm/multi_services_app/</guid><description>Pour commencer cette partie, on fait le ménage.
docker service rm $(docker service ls -q)
Nous allons maintenant reprendre l&amp;rsquo;application Dockercoin et la faire tourner dans notre cluster.
Nous allons construire les images, les envoyer sur le hub, puis les exécuter dans le cluster.
Ici nous sommes obligé d&amp;rsquo;envoyer les images dans un registry.
Avec la commande docker-compose up, toutes les images de nos services sont construite en local.</description></item><item><title>Avant Docker</title><link>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/before_docker/</link><pubDate>Mon, 08 Jun 2020 23:09:18 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/before_docker/</guid><description>Les applications étaient principalement toutes installées sur des Machines Virtuelles.
Certaines fois plusieurs applications partagent la même VM avec ses propres librairies, dépendances, fichiers de configurations&amp;hellip;
Les installations se sont ensuite automatisées avec Ansible, Chef, Puppet,&amp;hellip; mais il est très facile de modifier un fichier directement sur la machine sans changer le template.
Ce qui rend les environnements certaines fois non fiable.
Les Ops et Dev n&amp;rsquo;ont pas forcement une manière simple de partager les applications.</description></item><item><title>Après Docker</title><link>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/after_docker/</link><pubDate>Mon, 08 Jun 2020 23:09:18 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/after_docker/</guid><description>Les applications sont désormais deployées seules dans une image avec les dependances et configurations.
Dev et Prod peuvent facilement echanger l&amp;rsquo;application et la deployer en Production.
Les mises à jour ne neccessitent plus une reinstallation mais seulement un changement d&amp;rsquo;image.
De la même maniere, il est désormais très simple de revenir à une version précédente.</description></item><item><title>Alors, VM ou Conteneur ?</title><link>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/vm_container/</link><pubDate>Mon, 08 Jun 2020 23:09:18 +0200</pubDate><guid>https://zaggash.github.io/tp-iut-docker/introduction/why_docker/vm_container/</guid><description>La plupart du temps, les conteneurs tournent dans des VMs.
Les applications profitent des bénéfices de la contenerisation et la flexibilité des VMs.
Faire tourner des conteneurs dans une machine complétement physique ajoute des problématiques de scalabilitée.
Il n&amp;rsquo;y a pas de vérité, tout est une question de besoin !
VM Conteneur Lourd, dans l&amp;rsquo;ordre du Giga Léger, dans l&amp;rsquo;ordre du Mega Overhead de l&amp;rsquo;hyperviseur Performance native de l&amp;rsquo;hôte Chaque VMs à son propre OS Les conteneurs partagent l&amp;rsquo;OS de l&amp;rsquo;hôte Virtualisation Hardware Virtualisation de l&amp;rsquo;OS Démarrage dans l&amp;rsquo;ordre de la minute Démarrage de l&amp;rsquo;ordre de la milliseconde Isolation complète, donc plus sécrisée Isolation au niveau du processus, potentiellement moins sécurisée</description></item></channel></rss>
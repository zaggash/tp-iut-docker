[{"uri":"https://zaggash.github.io/tp-iut-docker/orchestration/installer-compose/","title":"Installer docker-compose","tags":[],"description":"","content":"Bien que nous puissions installer Docker Compose à partir des repos officiels Ubuntu, cette version n\u0026rsquo;est pas très à jour.\nNous allons donc installer Docker Compose à partir du repo github de Docker Compose .\nLe site de Docker propose une documentation pour l\u0026#39;installation .\n$ sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose $ docker-compose --version "},{"uri":"https://zaggash.github.io/tp-iut-docker/docker_linux/namespaces/","title":"Les Namespaces","tags":[],"description":"","content":"Les Namespaces jouent un rôle important dans les conteneurs.\nIls permettent de placer les conteneurs dans leur propre vu du système et limitent ce que l\u0026rsquo;on peux faire et voir.\nIl y a different type de namespaces:\n pid net mnt uts ipc user  Les namespaces sont parties intégrante du Kernel et sont actif dès le demmarage de l\u0026rsquo;OS.\nMême sans l\u0026rsquo;utilisation des conteneurs, il y a au moins un namespace de chaque type qui contient tous les processus du système.\nIls sont donc liés au système et créé grâce à deux Syscall principaux : clone() et unshare()\nLa commande unshare permet de faire appelle à ces Syscall.\nnsenter fait apelle au syscall setns() et nous permet d\u0026rsquo;inspecter les namespaces.\nQuand le dernier processus d\u0026rsquo;un namespace s\u0026rsquo;arrête, le namespace est detruit et toutes les ressources qui vont avec.\nOn les retrouve décrit par des fichiers dans /proc/\u0026lt;PID\u0026gt;/ns\nVérifier dans votre VM les namespaces utilisés par init ( PID 1) et dockerd (pidof dockerd)\n Créer son premier namespace net Le netns sera vu dans la partie suivante.\n UTS Nous allons utiliser le namespace uts.\nIl permet concrétement de choisir le hostname du conteneur.\n// Dans la VM $ hostname apinon-droplet-1 $ sudo unshare --uts /bin/bash // Ici on est dans le namespace // hostname my.name.is.bob # hostname my_name_is_bob  Ouvrir un nouveau terminal et vérifier le hostname de la VM.\n On peux quitter le namespace avec ctrl+d ou exit\nmnt On peut aussi isoler les points de montage.\nOuvrir deux terminaux sur la VM.\n// Terminal 1 (dans le namespace) $ sudo unshare --mount /bin/bash $ mount -t tmpfs none /tmp # ls -l /tmp // Terminal 2 (dans la VM) $ ls -l /tmp Nous avons monté un moint de montage privé dans notre namespace.\npid Les processus avec un PID namespace voit seulement les processus dans le même PID namespace.\nChaque PID namespace à sa propre arborescence (à partir de 1)\nSi le PID 1 se termine, alors le le namespace est terminé (sur Linux, si on kill le PID 1, on a un Kernel Panic)\n// On entre dans notre namespace $ sudo unshare --pid --fork /bin/bash # ps aux  Que se passe t-il ?\n Nous avons créé un PID namespace, mais Linux se base sur le point de montage /proc pour afficher les processus.\nNotre PID namespace à donc encore accès au PID de la VM, même s\u0026rsquo;il ne peux plus intéragir avec.\n// On entre dans notre namespace $ sudo unshare --pid --fork /bin/bash # pidof dockerd # kill -9 $(pidof dockerd) bash: kill: (7807) - No such process Pour contourner cela, la command unshare fournit l\u0026rsquo;option --mount-proc\n// On entre dans notre namespace $ sudo unshare --pid --fork --mount-proc /bin/bash # ps aux  Il n\u0026rsquo;est pas obligatoire de comprendre tout ce qui suit, mais une explication s\u0026rsquo;impose. Vous avez peux être remarqué le \u0026ndash;fork\nC\u0026rsquo;est une complexité due au fonctionnement du syscall unshare() qui exec() le processus en argument.\nSi on ne fork pas le processus qui lance le syscall, celui-ci va lancer le namespace puis se terminer dans l\u0026rsquo;OS, ce qui va donc terminer le namespace.\nEn utilisant --fork, unshare va dupliquer le processus après avoir créée le PID namespace. Puis lancer /bin/bash dans le nouveau processus.\n user Le user namespace permet de séparer les UID/GID entre l\u0026rsquo;hôte et le namespace.\nCela permet d\u0026rsquo;être root dans le namespace avec un utilisateur standard de l\u0026rsquo;hôte.\n// Notez que `unshare` est lancé sans `sudo` $ id uid=1000(alexxx) gid=1000(alexxx) groups=1000(alexxx) $ unshare --user /bin/bash # id id=65534(nobody) gid=65534(nogroup) groups=65534(nogroup) La séparation des UID dans docker compliquent le partage de fichier entre conteneurs.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/automatisation_image/dockerfile/","title":"Le Dockerfile","tags":[],"description":"","content":"Un Quoi ? Le dockerfile est en gros la recette pour créer une oimage Docker.\nIl contient toutes les instruction pour indiqué au daemon quoi faire et comment doit être construite notre image.\nLa commande à utiliser est docker build\nNotre premier Dockerfile Vous pouvez utliser la commande suivant pour nettoyer votre environnement docker du travail précédent.\ndocker rm -f $(docker ps -q); docker system prune -af --volumes\nCes commandes suppriment les conteneurs actifs puis les volumes/images/conteneurs inactifs\n FROM et RUN Nous allons construire ensemble le premier Dockerfile.\nLe DockerFile doit être dans un dossier vide.\n$ mkdir mon_image Puis ajouter un Dockerfile dans ce répertoire.\n$ cd mon_image $ touch Dockerfile Lancer l\u0026rsquo;éditeur de votre choix pour modifier le Dockerfile\nFROMubuntuRUN apt-get updateRUN apt-get -y install figlet FROM indique l\u0026rsquo;image de base pour notre build. RUN Execute notre commande pendant le build, RUN ne doit pas être interactif, d\u0026rsquo;où le -y durant le apt-get.  Sauvegarder votre Dockerfile, puis on execute le build\n$ docker build -t figlet .  -t indique le nom de notre image (nous reviendrons sur le nommage juste après) . indique l\u0026rsquo;emplacement du contexte de notre build.  Sending build context to Docker daemon 2.048kB\nle contexte est envoyé à dockerd sous forme de tarball, utile si on build sur une machine distante.\nNous pouvons désormais utiliser notre nouvelle image et executer le programme figlet\n$ docker run -ti figlet root@7d038d8e1960:/# figlet Good Job CMD et ENTRYPOINT Afin de lancer automatiquement un processus dans notre image au lieu de l\u0026rsquo;executer dans un shell, nous pouvons utiliser CMD ou ENTRYPOINT.\n  CMD permet de definir une commande par default quand aucune n\u0026rsquo;est donnée au lancement du conteneur.\nUn seul CMD est autorisé, seul le dernier est pris en compte.\n  ENTRYPOINT defini une commande de base.\nLe CMD ou les arguments en ligne de commande seront les paramètres de l\u0026rsquo;ENTRYPOINT\n  Editer le Dockerfile précédent pour ajouter un ENTRYPOINT et un CMD afin d\u0026rsquo;afficher I Love Containers avec figlet.\nla conteneur sera lancé avec docker run ilovecontainers\n Avec cette dernière image, je veux lancer un conteneur en mode interactif sous bash. Quel serait la marche a suivre ? Vous pouvez chercher dans la documentation de Docker pour vous familiariser avec le site:\nDocumentation: Docker build  Tips and Tricks On ne va pas trop rentrer dans les details, mais il faut savoir qu\u0026rsquo;il y a quelque bonne habitude à respecter lorsque l\u0026rsquo;on créé un Dockerfile.\nEn voici quelques une pour ne pas être étonné de les voir, si vous tomber sur certain Dockerfile.\n Il faut reduire le nombre de layers Ne pas installer des paquets inutiles Supprimer les fichiers temporaires et caches avant de changer de layer.\nSachant que chaque layer est indépendant, supprimer un fichier créé dans un layer précedant ne reduira pas la taille de l\u0026rsquo;image.  Pour en savoir plus, le site de Docker est une bonne base d\u0026rsquo;information pour commencer. Je reste dispo pour les questions si besoin.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/docker_linux/reseaux/network_drivers/","title":"Les Pilotes Réseau","tags":[],"description":"","content":"Docker inclut plusieurs drivers Réseau que l\u0026rsquo;on peux choisir avec l\u0026rsquo;option --net \u0026lt;driver\u0026gt;\n bridge (par default) none host container  Le bridge Par default le conteneur obtient un interface virtuel eth0 en plus de son interface de bouclage (127.0.0.1)\nCette interface est fournit par une paire de veth.\nElle est connecté au Bridge Docker appelé docker0 par default.\nLes adresses sont alloué dans un reseau privé interne 172.17.0.0/16 par défault.\nLe traffic sortant passe par une régle iptables MASQUERADE, puis le traffic entrant et naté par DNAT.\nLes régles sont automatiquement gérée par Docker.\nLe null driver Par grand chose à dire sur celui-là, Si ce n\u0026rsquo;est que le conteneur ne peux pas envoyer ni recevoir de traffic.\nIl obtient uniquement son adresse local lo\nLe host driver Le conteneur executé avec ce driver voit et accède au interfaces de l\u0026rsquo;hôte.\nLe traffic n\u0026rsquo;est donc pas naté et ne passe pas par une veth.\nCe driver permet donc d\u0026rsquo;avoir les performances natives de la carte réseau. Très pratique dans des applications sensiblent à la latence (Voip, streaming, \u0026hellip;)\nLe driver container Celui-ci est un peu spécial car il permet de réutiliser la stack réseau d\u0026rsquo;un autre conteneur.\nLes deux conteneurs partagent la même interface, IP, routes, \u0026hellip;\nIls peuvent communiquer au travers de 127.0.0.1.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/docker/travailler_images/image_vs_conteneur/","title":"Image vs Conteneur","tags":[],"description":"","content":"Une image n\u0026rsquo;est pas un conteneur ! Une image est un système de fichiers en lecture seul\nUn conteneur est processus qui s\u0026rsquo;execute dans une copie de ce système de fichiers.\nPour accélérer le démarrage et optimiser les accès disque, plutôt que de copier l\u0026rsquo;image entière, on utilise ici du Copy-On-Write.\nPlusieurs conteneurs peuvent donc utiliser la même image sans dupliquer les données.\nSi une image est en lecture seul, on ne modifie pas une image, on en crée une nouvelle.\nNous avons utlisé l\u0026rsquo;image ubuntu tout a l\u0026rsquo;heure.\nNous pouvons inspecter ses layers de la manière suivante\n$ docker image history ubuntu:latest IMAGE CREATED CREATED BY SIZE COMMENT 1d622ef86b13 7 weeks ago /bin/sh -c #(nop) CMD [\u0026#34;/bin/bash\u0026#34;] 0B \u0026lt;missing\u0026gt; 7 weeks ago /bin/sh -c mkdir -p /run/systemd \u0026amp;\u0026amp; echo \u0026#39;do… 7B \u0026lt;missing\u0026gt; 7 weeks ago /bin/sh -c set -xe \u0026amp;\u0026amp; echo \u0026#39;#!/bin/sh\u0026#39; \u0026gt; /… 811B \u0026lt;missing\u0026gt; 7 weeks ago /bin/sh -c [ -z \u0026#34;$(apt-get indextargets)\u0026#34; ] 1.01MB \u0026lt;missing\u0026gt; 7 weeks ago /bin/sh -c #(nop) ADD file:a58c8b447951f9e30… 72.8MB Les données relatives aux images et aux conteneurs sont stockées dans: /var/lib/docker/\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/docker/travailler_conteneurs/","title":"Travailler avec les conteneurs","tags":[],"description":"","content":"Hello World Dans votre nouvel environement, tapez la commande suivante:\n$ docker run busybox echo hello world hello world  Nous avons utilisé une des plus simple et petite image: busybox busybox est souvent utilisé dans les systÈmes emabrqués. Nous avons lancé un simple processus et affiché hello world La premiere fois que l\u0026rsquo;on lance un conteneur, l\u0026rsquo;image est chargée sur la machine, cela explique les lignes supplémentaires.  Conteneur interactif Lançons un conteneur un peu plus sympa\n$ docker run -it ubuntu root@ae1c076701b7:/#   Nous venons de lancer un simple conteneur sous ubuntu\n  -it est un raccourci pour -i -t.\n  -i nous connecte au stdin du conteneur\n  -t nous donne un pseudo-terminal dans le conteneur\n    Utiliser le conteneur Essayez de lancer figlet dans notre conteneur\nroot@ae1c076701b7:/# figlet bash: figlet: command not found Nous avons besoin de l\u0026rsquo;installer\nroot@ae1c076701b7:/# apt-get update \u0026amp;\u0026amp; apt-get install figlet -y [...] root@ae1c076701b7:/# figlet hello-world _ _ _ _ _ | |__ ___| | | ___ __ _____ _ __| | __| | | \u0026#39;_ \\ / _ \\ | |/ _ \\ ____\\ \\ /\\ / / _ \\| \u0026#39;__| |/ _` | | | | | __/ | | (_) |_____\\ V V / (_) | | | | (_| | |_| |_|\\___|_|_|\\___/ \\_/\\_/ \\___/|_| |_|\\__,_| Conteneurs et VMs Sortir du conteneur avec exit et lancer la commande à nouveau figlet hello-world, cela fonctionne-t-il ?\n Nous avons lancé un conteneur ubuntusur une machine hôte linux. Ils ont des paquets differants et sont independants, même si l\u0026rsquo;OS est identique..  Mais où est mon conteneur ? Notre conteneur à maintenant un status `stopped. Il est toujours présent sur le disque de la machine mais tous les processus sont arrétés.\nNous pouvons lancer un nouveau conteneur, et lancer figlet à nouveau\nroot@b6cb64d4bddc:/# figlet bash: figlet: command not found Nous avons lancé un tout nouveau conteneur avec la même image de base ubuntu et figlet n\u0026rsquo;est pas installé.\nIl est possible re reutiliser un conteneur qui à été arrêté mais ce n\u0026rsquo;est pas la philosophie des conteneurs.\nVoyez un conteneur comme un processus à usage unique, si l\u0026rsquo;on veux réutiliser un conteneur personalisé, on crée une image\nCela permet de garder le coté immuable d\u0026rsquo;un conteneur et de pouvoir le partager de facon fiable.\nNous verrons dans un prochain chapitre comment personnaliser une image !\n "},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/pourquoi_docker/","title":"Pourquoi docker ?","tags":[],"description":"","content":"Avant:\n application en un seul bloc Cycle de developement long Un seul environement de prod Scalabilitée lente  Aujourd\u0026rsquo;hui:\n Architecture orientée microservices Mise a jour fréquente et rapide Environement multiple Besoin de scalabilité rapide  "},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/","title":"Introduction","tags":[],"description":"","content":"Partie 1 Introduction Introduction à docker et au concept de conteneurs.\nOn ne lancera pas (tout de suite) de conteneur dans ce chapitre !\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/orchestration/compose-app/","title":"Une application Docker Compose","tags":[],"description":"","content":"Docker fournit un repository Github avec plusieurs applications pour tester Docker.\nNous allons utiliser l\u0026rsquo;application voting-app pour essayer Docker Compose.\nJ\u0026rsquo;ai préparer l\u0026rsquo;application dnas le repo du TP.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/docker_linux/reseaux/inside_network/","title":"Dans le Réseau","tags":[],"description":"","content":"On peux lister les réseaux avec docker network ls\n$ docker network ls NETWORK ID NAME DRIVER SCOPE a5fa804dcca5 bridge bridge local a5a200b4762b host host local b35f65ab844b none null local On peux considérer un réseau comme un Virtual Switch.\nDocker va lui assigner automatiquement un sous-réseau puis une IP aux conteneurs associés.\nLes conteneurs peuvent faire partie de plusieurs réseaux à la fois.\nLes noms des conteneurs sont résolus via un serveur DNS embarqué dans le Docker daemon.\nIl existe aussi un driver multi-hôtes utilisé lors de la mise en cluster de plusieurs machines (un Cluster Swarm)\nCe driver, appelé overlay fonctionnent au traver de lien VXLAN. Nous reviendrons sur celui-ci un peu plus tard.\nUn réseau, deux conteneurs, Créer un réseau devops\n$ docker network create devops 8a5841273868138b581a8c663e9a042f181a1a52c0028c21988ffd474c117610 Vous pouvez le voir avec docker network ls\nMaintenant, lancer un conteneur sur ce réseau et donné lui un *nom reconnaissable.\n$ docker run -d --name AppDev --net devops hashicorp/http-echo -text \u0026#34;Mon AppDev\u0026#34; Maintenant, lancer un autre conteneur dans ce même réseau\n$ docker run -ti --net dev alpine sh / # Essayer de lancer un ping vers votre premier conteneur AppDev\n On peux inspecter le réseau avec docker inspect devops\n$ docker inspect devops [ { \u0026#34;Name\u0026#34;: \u0026#34;devops\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;8be916360cbc400758d107e47e02a9890d37da0fe3cb0a3a11acde60173a03de\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2020-06-14T01:49:07.632816857Z\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.20.0.0/16\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;2496236a9109045a1cfb17cd237e84208fe2b3fee7b861e212aeaf7bce9bf61c\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;AppDev\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;19a945be9b13b373dc49c840c9871bfa60ed7bfba163c7a93e763b7f016102dc\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:14:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.20.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] Dans mon cas on peux voir que devops a un sous réseau en 172.20.0.0/16\nPuis la définition de mon conteneur avec l\u0026rsquo;IP 172.20.0.2/16\nMaintenant sur la VM, lister les interface réseau\n$ ip a [...] 262: br-8be916360cbc: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:f3:81:04:97 brd ff:ff:ff:ff:ff:ff inet 172.20.0.1/16 brd 172.20.255.255 scope global br-8be916360cbc valid_lft forever preferred_lft forever inet6 fe80::42:f3ff:fe81:497/64 scope link valid_lft forever preferred_lft forever 264: vethcbea7f9@if263: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue master br-8be916360cbc state UP group default link/ether 96:56:cf:87:0d:3d brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet6 fe80::9456:cfff:fe87:d3d/64 scope link valid_lft forever preferred_lft forever Vous pouvez voir voir les interfaces de la VM, le bridge docker0.\nPuis deux interfaces br-8be916360cbc, vethcbea7f9@if263 qui sont le bridge et l\u0026rsquo;interface veth coté VM.\nOn peux voir ça aussi avec brctl\n$ brctl show bridge name\tbridge id\tSTP enabled\tinterfaces br-8be916360cbc\t8000.0242f3810497\tno\tveth1eecb09 docker0\t8000.02422beae43c\tno\tOn peux aller un peu plus loin Créér un deuxième réseau prod Lancer un conteneur dans ce reseau prod\n$ docker run -d --name AppProd hashicorp/http-echo -text \u0026#34;Production\u0026#34; Obtenir l\u0026rsquo;IP de AppDev et AppProd\n$ docker run --rm --net container:AppDev alpine ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 265: eth0@if266: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u0026gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:14:00:02 brd ff:ff:ff:ff:ff:ff inet 172.20.0.2/16 brd 172.20.255.255 scope global eth0 valid_lft forever preferred_lft forever $ docker run --rm --net container:AppProd alpine ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 268: eth0@if269: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN\u0026gt; mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:18:00:02 brd ff:ff:ff:ff:ff:ff inet 172.24.0.2/16 brd 172.24.255.255 scope global eth0 valid_lft forever preferred_lft forever On a donc AppDev : 172.20.0.2/16 et AppProd : 172.24.0.2/16\nEssayer de pinger AppProd à partir de AppDev. Que se passe t-il ?\n On a vu que Docker est lié au Kernel, nous allons très simplement connecter AppDev et AppProd sans passer par Docker.\nNous allons créer une paire de Veth, puis connecter un bout au bridge devops et un autre dans le namespace du conteneur AppProd\n# On crée la paire de veth $ sudo ip link add name int_hote type veth peer name int_conteneur # On associe in_hote au bridge $ sudo ip link set int_hote master br-8be916360cbc up # On voit nos interface dans la VM $ ip a | grep int 270: int_conteneur@int_hote: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 271: int_hote@int_conteneur: \u0026lt;NO-CARRIER,BROADCAST,MULTICAST,UP,M-DOWN\u0026gt; mtu 1500 qdisc noqueue master br-8be916360cbc state LOWERLAYERDOWN group default qlen 1000 Il nous faut trouver le pid de AppProd pour associer l\u0026rsquo;autre veth à son network namespace\n$ ps ax | grep \u0026#39;Production\u0026#39; 3146 ? Ssl 0:00 /http-echo -text Production Le PID est le 3146\n$ ip link set int_conteneur netns 3146 On va utliser la commande nsenter pour se ballader dans les namespaces.\n$ nsenter -n -u -t 3146 root@69421ba25609:~# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 268: eth0@if269: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:18:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.24.0.2/16 brd 172.24.255.255 scope global eth0 valid_lft forever preferred_lft forever 270: int_conteneur@if271: \u0026lt;BROADCAST,MULTICAST\u0026gt; mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 26:d7:1f:f9:fb:77 brd ff:ff:ff:ff:ff:ff link-netnsid 0 Maintenant on configure l\u0026rsquo;interface dans le conteneur AppProd.\nroot@69421ba25609:~# ip link set int_conteneur name eth1 up root@69421ba25609:~# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 268: eth0@if269: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:18:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.24.0.2/16 brd 172.24.255.255 scope global eth0 valid_lft forever preferred_lft forever 270: eth1@if271: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 26:d7:1f:f9:fb:77 brd ff:ff:ff:ff:ff:ff link-netnsid 0 # # Rappel, le sous reseau devops est 172.20.0.0/16 # On va prendre un IP dans ce reseau : 172.20.0.100/16 # root@69421ba25609:~# ip addr add 172.20.0.100/16 dev eth1 root@69421ba25609:~# ip route add default via 172.20.0.1  Essayer maintenant de nouveau de pinger AppProd à partir de AppDev.\nConnecter vous au namespace avec nsenter pour jouer avec ;) Que se passe t-il ?\n Supprimer maintenant les deux conteneurs.\nObserver les interfaces réseau au niveau de la VM.\n "},{"uri":"https://zaggash.github.io/tp-iut-docker/automatisation_image/dockerhub/","title":"Le Docker Hub","tags":[],"description":"","content":"Le Nommage Les images docker doivent respecter un certain schema de nommage pour être partager dans un registry.\nIl y a 3 espaces de noms:\n Les images officielles\nalpine, ubuntu, python  Les images officielles sont selectionées par Docker.\nElles sont dirctement dans le l\u0026rsquo;espace de nom racine.\nCe sont généralement des images de tiers reconnus.\nhttps://hub.docker.com  Les images d\u0026rsquo;utilisateurs (ou d\u0026rsquo;organisations)\nzaggash/random  L\u0026rsquo;espace de nom utilisateur contient les images des utilisateurs ou organisations.\nzaggash est l\u0026rsquo;utilisateur dockerhub.\nrandom est le nom de l\u0026rsquo;imgage.\n Les images appartenant à un registry autre que le DockerHub\nregistry.mondns.fr:5000/mon_repo/mon_image  Ce nom est composé de l\u0026rsquo;adresse IP ( ou DNS) du registry et du port.\nPuis on retrouve la même logique que précédemment.\nLes tags Vous avez peux être déjà remarqué mais les images ont un tag de version associé à leur nom, le tag par défaut est latest\n$ docker pull zaggash/random Using default tag: latest latest: Pulling from zaggash/random 76df9210b28c: Pull complete Digest: sha256:f1eb69bbb25b4f0b88d2edfe1d5837636c9e5ffaad0e96a11c047005a882f049 Status: Downloaded newer image for zaggash/random:latest docker.io/zaggash/random:latest Le tag defini une variante, la version d\u0026rsquo;une image.\n Si vous n\u0026rsquo;avez pas de compte sur le DockerHub, je vous invite à en créer un, c\u0026rsquo;est gratuit \u0026raquo; Inscription Essayer de poussez votre image créée précédement, dans votre espace de nom avec docker login et docker push\nVous devrez certainement la renommer avec la commande docker tag \u0026raquo; Documentation Docker CLI   Le Hub Petite Pause !\nOn essai de tous se retrouver pour une présentation de l\u0026rsquo;interface, et une session Questions/Réponses si besoin.\n  Les images officielles, les images utilisateurs/organisations Les Tags Présentation de l\u0026rsquo;integration avec Github Builds automatisés Les Webhooks  "},{"uri":"https://zaggash.github.io/tp-iut-docker/docker_linux/reseaux/","title":"Les Réseaux","tags":[],"description":"","content":"Le serveur Nginx Pour avoir accès au service web de nginx il va falloir exposer son port. Lancer l\u0026rsquo;image nginx du Dockerhub qui contient un serveur web basique.\n$ docker run -d -p 8080:80 nginx Unable to find image \u0026#39;nginx:latest\u0026#39; locally latest: Pulling from library/nginx 8559a31e96f4: Pull complete 8d69e59170f7: Pull complete 3f9f1ec1d262: Pull complete d1f5ff4f210d: Pull complete 1e22bfa8652e: Pull complete Digest: sha256:21f32f6c08406306d822a0e6e8b7dc81f53f336570e852e25fbe1e3e3d0d0133 Status: Downloaded newer image for nginx:latest 8fe2d550ac86b4bb6f544710f4f65ffcc0f4728a2cf52f5b8455e0112b284ce0 -p \u0026lt;ip\u0026gt;:8080:80 Ici on expose le port 80 du conteneur nginx sur le port 8080 de la VM\nPar default, le port de la VM écoute sur 0.0.0.0\n$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b1fa3fc64a2f nginx \u0026#34;/docker-entrypoint.…\u0026#34; 3 seconds ago Up 2 seconds 0.0.0.0:8080-\u0026gt;80/tcp stupefied_shaw Sur l\u0026rsquo;output ci-dessus, ou voit bien la colonne PORTS qui recapitule les ports ouverts.\nOn lance un curl pour verifier que l\u0026rsquo;on a bien un HTTP 200\n$ curl -sLI 127.0.0.1:8080 HTTP/1.1 200 OK Server: nginx/1.19.0 Date: Sat, 13 Jun 2020 23:04:53 GMT Content-Type: text/html Content-Length: 612 Last-Modified: Tue, 26 May 2020 15:00:20 GMT Connection: keep-alive ETag: \u0026#34;5ecd2f04-264\u0026#34; Accept-Ranges: bytes  Essayer de lancer un autre conteneur nginx qui écoute sur le port 8080 uniquement sur localhost. Que se passe t - il ?\n Supprimer maintenant tous les conteneurs.\nEssayer de lancer un conteneur qui publie le port 80 sur toutes les interfaces et le port 8080 en local.\n "},{"uri":"https://zaggash.github.io/tp-iut-docker/docker/travailler_conteneurs/arriere_plan/","title":"Conteneurs en arrière-plan","tags":[],"description":"","content":"Un conteneur non-interactif Nous allons lancer un conteneur tout simple qui affiche des nombres aléatoires chaque seconde.\n$ docker run zaggash/random 23008 19194 17802 16235 8189 667  Ce conteneur continuera de s\u0026rsquo;executer indéfiniement. Un ctrl+c permet de l\u0026rsquo;arrêter.  en arrière-plan Nous pouvons lancer ce conteneur de la meme manière mais en arrier plan avec l\u0026rsquo;option -d\n$ docker run -d zaggash/random a5a20f1f8897d6b7a7644a322141ad74a3c21e28530b11cf10ef583ba539e55c On ne voit plus la sortie standard du conteneur, mais le daemon dockerd collecte toujours stdin/stdout du conteneur et les écrit dans un fichier de log.\nLa chaîne de caractères est l\u0026rsquo;ID complet de notre conteneur.\nPetit rappel du chapître précedent.\nOn peut voir le processus dockerd, PID 7807 qui contient la socket de containerd en argument.\nPuis notre processus enfant 8247, executé par runc, PID 8217 lui même demarré par containerd, PID 2656\n $ ps fxa | grep dockerd -A 3 [...] 2656 ? Ssl 42:56 /usr/bin/containerd 8217 ? Sl 0:00 \\_ containerd-shim -namespace moby -workdir /var/lib/containerd/io.containerd.runtime.v1.linux/moby/027b6c72b74f510b3403a3cd246e3c8c802034960cb82bf45dad8278f0e21d6c -address /run/containerd/containerd.sock -containerd-binary /usr/bin/containerd -runtime-root /var/run/docker/runtime-runc 8247 ? Ss 0:00 \\_ /bin/sh -c while echo $RANDOM;do sleep 1;done -- 7807 ? Ssl 1:03 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock [...] Un processus conteneurisé est un proccessus system comme un autre. On peut le voir avec un ps on peux faire l\u0026rsquo;analyser avec un strace, lsof,\u0026hellip;\nPlus de commandes Verifier l\u0026rsquo;état de notre conteneur Verifier les conteneurs en cours d\u0026rsquo;execution avec la commande docker ps\n$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a5a20f1f8897 zaggash/random \u0026#34;/bin/sh -c \u0026#39;while e…\u0026#34; 5 minutes ago Up 5 minutes crazy_khorana L\u0026rsquo;API nous retourne:\n l\u0026rsquo;ID tronqué de notre conteneur l\u0026rsquo;image utilisé par le conteneur l\u0026rsquo;etat du conteneur (Up) un nom généré aléatoirement  Lancer 2/3 conteneurs supplémentaires et verifier que docker ps nous retourne tous les conteneurs.\n Quelques commandes utiles 1 - Voir les ID des conteneurs Si vous voulez lister les seulement les ID des conteneurs, l\u0026rsquo;option -q renvoi une colonne avec sans les Entête. Cet argument est particulièrement utile pour le scripting.\ndocker ps -q eaf444d185be aaeb4643ae39 a5a20f1f8897 2 - Voir les logs des conteneurs Docker garde les logs stderr et stdout de chaques conteneurs. Verifions ça avec notre premier conteneur\n$ docker logs a5a [...] 5412 3585 13237 20376 29438 Docker nous retourne la totalité des logs du conteneur.\nPour eviter d\u0026rsquo;être polluer par tout ça, nous pouvons utliser l\u0026rsquo;argument --tail et extraire les dernieres lignes\n$ docker logs --tail 5 a5a 12893 32068 25356 571 16054 Pour voir les logs en temps réél, on peux utiliser l\u0026rsquo;argument -f\n$ docker logs --tail 5 -f a5a 6644 28412 3315 22610 27692 3136 9107 20481 ^C Nous voyons les 5 derniere ligne de logs puis l\u0026rsquo;affichage en temps réél. ctrl+c pour quitter.\n3 - Arrêter un conteneur Nous pouvons arrêter un conteneur de deux manières.\n avec un kill avec un stop  Le kill va arrêter le contaneur de manière immediate avec un signal KILL.\nLe stop envoie un signal TERM et peut être intercepté par l\u0026rsquo;application pour terminer le processus.\nAprès 10s si le processus n\u0026rsquo;est pas arrêté, Docker envoi un KILL\nOn peut tester ça avec notre conteneur\n$ docker stop a5a a5a Nous voyons bien que le terminal nous rend la main après une dizaine de seconde.\n Docker envoi un TERM Le conteneur ne réagit pas à ce signel, c\u0026rsquo;est une simple boucle en Shell. 10s après, le conteneur est toujours actif, alors Docker envoi un KILL et termine le conteneur.  Maintenant, on va arrêter les conteneurs restant avec un kill en utilisant les commandes vu précédemment\n$ docker kill $(docker ps -q) eaf444d185be aaeb4643ae39 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Nous voyons ici que les conteneurs ont été arrêté immediatement.\n$ docker ps -a docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES eaf444d185be zaggash/random \u0026#34;/bin/sh -c \u0026#39;while e…\u0026#34; 29 minutes ago Exited (137) 3 minutes ago friendly_chatelet aaeb4643ae39 zaggash/random \u0026#34;/bin/sh -c \u0026#39;while e…\u0026#34; 29 minutes ago Exited (137) 3 minutes ago recursing_dirac a5a20f1f8897 zaggash/random \u0026#34;/bin/sh -c \u0026#39;while e…\u0026#34; 44 minutes ago Exited (137) 8 minutes ago crazy_khorana "},{"uri":"https://zaggash.github.io/tp-iut-docker/docker/travailler_images/image_interactive/","title":"Création Image Interactive","tags":[],"description":"","content":"Créer une image à partir d\u0026rsquo;un conteneur Il est possible de créer une image partir d\u0026rsquo;un conteneur et de ses modifications.\nMeme si cette solution n\u0026rsquo;est pas la plus utilisée, elle peut être utilsée à des fins de tests ou de sauvegarde.\nReprenons notre exemple avec figlet pour créér une nouvelle image à partir du conteneur. Pour cela nous allons:\n Lancer un conteneur avec une image de base de votre choix. Installer un programme manuellement dans le conteneur Puis utiliser les nouvelles commandes : docker commit, docker tag et docker diff docker diff pour voir les changement effectuer dans le conteneur. docker commit pour convertir le conteneur en nouvelle image docker tag pour renommer l\u0026rsquo;image.  Essayez par vous même, sinon je reste disponible pour toutes questions.\n Dans le prochain chapitre, nous allons apprendre à automatiser le build avec un Dockerfile\n "},{"uri":"https://zaggash.github.io/tp-iut-docker/docker/travailler_images/","title":"Travailler avec les images","tags":[],"description":"","content":"Qu\u0026rsquo;est ce qu\u0026rsquo;une image ? Une image est un ensemble de fichiers et de metadata.\n Les fichiers constituent le FileSystem de notre conteneur. les metadata peuvent etre de differantes formes  le créateur de l\u0026rsquo;image les variables d\u0026rsquo;environement les commandes à executer    Les images sont en faite une superposition de couches appelé layers\nChaque layer ajoute, modifie ou supprime un fichier et/ou une metadata.\nLes images peuvent partager des layers, ce qui permet d\u0026rsquo;optimiser l\u0026rsquo;utilisation de l\u0026rsquo;espace disque, les transfers reseaux\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/docker/","title":"Docker","tags":[],"description":"","content":"Partie 2 Docker Dans ce chapitre nous allons voir plusieurs type de conteneur.\nPuis en apprendre un peu plus sur leurs fonctionnement.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/architecture/architecture_interne/","title":"Docker Engine","tags":[],"description":"","content":"Le Docker Engine est divisé en plusieurs parties.\n dockerd (REST API, authentification, reseaux, stockage) : Fait appel à containerd containerd (Gère la vie des conteneurs, push/pull les images) runc (Lance l\u0026rsquo;application du conteneur) containerd-shim (Par conteneur; permet de separer le processus et RunC)  Plusieurs fonctionnalitées sont progressivement deleguées du Docker Engine à containerd\nDes exercices du TP permettrons de verifier cela après l\u0026rsquo;installation\n "},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/architecture/","title":"Architecture","tags":[],"description":"","content":"Lorsque l\u0026rsquo;on installe Docker, on installe plusieurs composants.\nIl y a le Docker Engine et la CLI.\n Le Docker Engine est un demon qui tourne an arrière plan Les interactions avec ce daemon se font via une API REST par un Socket. Sous Linux, ce socket est un socket Unix : /var/run/docker/sock Il est également possible d\u0026rsquo;utiliser un Socket TCP avec authentification TLS. Le Docker CLI communique avec le daemon via cette Socket.  "},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/pourquoi_docker/deploiement_complexe/","title":"Deploiements complexes","tags":[],"description":"","content":"Les deploiements deviennent de plus en plus compliqués, voici quelques exemples.\nDe nombreuse couches applicatives:\n Language (php, go, JS,\u0026hellip;) Framework Bases de données  Plusieurs environements cible:\n Machines local pour les tests Environements de Dev, QA, Pre-Prod, Prod Serveurs locaux, Cloud  "},{"uri":"https://zaggash.github.io/tp-iut-docker/automatisation_image/github/","title":"[Optionel] Github","tags":[],"description":"","content":"Pour aller plus loin\u0026hellip; Si vous le sentez, vous pouvez créer un repo sur Gihub pour pousser votre Dockerfile créé précédemment.\nPuis configurer un build automatique de votre Dockerfile gràace au DockerHub.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/docker_linux/volumes/","title":"Les Volumes","tags":[],"description":"","content":"Les volumes permettent plusieurs choses:\n Passer outre le Copy On Write et utiliser les performances native des disques. Partager des dossiers et fichiers entre les conteneurs Partager des dossiers et fichiers entre l\u0026rsquo;hôte et les conteneurs Utiliser des points de montage distant  Nous aloons voir comment utiliser un volume:\n Dans un Dockerfile Au demarrage avec l\u0026rsquo;option -v En utilisant un volume nommé   La persistance des données Illustrons l\u0026rsquo;état par défaut des données après l\u0026rsquo;arrêt d\u0026rsquo;un conteneur\n$ docker container run -ti --name c1 alpine sh On va créer un dossier et un fichier à l\u0026rsquo;intérieur\n$ mkdir /mon_dossier \u0026amp;\u0026amp; cd /mon_dossier \u0026amp;\u0026amp; touch monfichier.txt Nous allons maintenant voir que le layer R/W du conteneur n\u0026rsquo;est pas accessible depuis l\u0026rsquo;hôte.\nCommençons par quitter le conteneur\n$ exit On va inspecter le notre conteneur pour trouver l\u0026rsquo;emplacement du layer.\nOn peut utiliser la commande inspect et chercher la le mote clef GraphDriver\n$ docker container inspect c1 On peux egalement utiliser la sortie avancé grâce au Template Go et voir directement l\u0026rsquo;information.\n$ docker container inspect -f \u0026#39;{{ json .GraphDriver }}\u0026#39; c1 | jq Vous devriez avoir un output qui ressemble à ça:\n{ \u0026quot;Data\u0026quot;: { \u0026quot;LowerDir\u0026quot;: \u0026quot;/var/lib/docker/overlay2/0b144df858ed09133fb9de89026b91cb1a8ecacb1464466cff9479f2267b69a0-init/diff:/var/lib/docker/overlay2/3385f7f394c776c48b391cd6e407816d3026cea3ff9f5526f05d631ff6b4ae55/diff\u0026quot;, \u0026quot;MergedDir\u0026quot;: \u0026quot;/var/lib/docker/overlay2/0b144df858ed09133fb9de89026b91cb1a8ecacb1464466cff9479f2267b69a0/merged\u0026quot;, \u0026quot;UpperDir\u0026quot;: \u0026quot;/var/lib/docker/overlay2/0b144df858ed09133fb9de89026b91cb1a8ecacb1464466cff9479f2267b69a0/diff\u0026quot;, \u0026quot;WorkDir\u0026quot;: \u0026quot;/var/lib/docker/overlay2/0b144df858ed09133fb9de89026b91cb1a8ecacb1464466cff9479f2267b69a0/work\u0026quot; }, \u0026quot;Name\u0026quot;: \u0026quot;overlay2\u0026quot; } Depuis l\u0026rsquo;hôte, si on regarde l\u0026rsquo;emplacement du dossier contenu dans la key UpperDir, on peux voir que notre dossier /mon_dossier et notre fichier monfichier.txt sont là.\nExecuter la commande suivante pour voir le contenu de notre dossier /mon_dossier:\n$ ls /var/lib/docker/overlay2/[ID_LAYER]/diff/mon_dossier Que se passe t-il si notre conteneur venait à être supprimé ?\n$ docker container rm c1  Il semble que le dossier UpperDir ci-dessus, n\u0026rsquo;existe plus. Pouvez vous le confirmer ?\nEssayer de lancer de nouveau un ls\n Cela prouve que les données dans un conteneur ne sont pas persistante, elles sont supprimées en même temps que le conteneur.\nDefinir un volume dans un Dockerfile Nous allons créér un Dockerfile basé sur alpine et definir /mon_dossier en tant que volume.\nCela signifie que tout ce que sera écrit par un conteneur dans /mon_dossier existera en dehors du layer R/W du conteneur.\nUtiliser le Dockerfile suivant:\nFROMalpineVOLUME [\u0026#34;/mon_dossier\u0026#34;]ENTRYPOINT [\u0026#34;/bin/sh\u0026#34;] On definit ici /bin/sh en Entrypoint afin d\u0026rsquo;avoir un shell en mode intéractif sans devoir spécifier de commande.\n Nous pouvons alors lancer la création de l\u0026rsquo;image\n$ docker image build -t img1 . On peux alors lancer notre conteneur en mode intéractif à partir de cette image.\n$ docker container run -ti --name c2 img1 /# On peux donc maintenant aller dans /mon_dossier et créer un fichier.\n/# cd /mon_dossier /# touch hello.txt /# ls hello.txt On peux quitter le conteneur en le laisant tourner en arrère plan.\nIl faut utiliser la combinaison de raccourcis : ctrl+P/ctrl+Q\nPuis vérifier que le conteneur est toujours actif.\n$ docker ps  Le conteneur c2 devrait être listé\n On va alors inspecter ce conteneur pour connaître l\u0026rsquo;emplacement de notre volume sur la VM.\nOn va utiliser directement les templates GO mais on pourrai utiliser un docker inspect puis chercher à la main la clef Mount\n$ docker inspect -f \u0026#39;{{ json .Mounts }}\u0026#39; c2 | jq Vous devriez avoir une sortie qui ressemble à ca:\n[ { \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;2d47da3c88436afa4b35b084ba0060009066b26b042ee7b161b1d3215f1b06fd\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/2d47da3c88436afa4b35b084ba0060009066b26b042ee7b161b1d3215f1b06fd/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/mon_dossier\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;\u0026#34; } ] Cette sortie montre que le volume /mon_dossier est situé dans /var/lib/docker/volumes/[ID_VOLUME]/_data\nRemplacer le chemin par le votre et vérifier que le fichier hello.txt est bien présent.\nOn peut maintenant supprimer c2\n$ docker rm -f c2 Valider que le fichier est toujours disponible à l\u0026rsquo;emplacement précédent.\nDefinir un volume en mode intéractif On a vu comment définir un volume via un Dockerfile, on peut aussi le définir au lancement avec l\u0026rsquo;option -v\nExecutons un conteneur à partir de l\u0026rsquo;image alpine, on utilisera l\u0026rsquo;option -d pour le passer en arrière plan.\nAfin que le processus PID1 du conteneur reste actif, on utilise une commande qui pinger 1.1.1.1 en continue et ecrire le résultat dans /mon_dossier.\n$ docker run -d --name c3 -v /mon_dossier alpine sh -c \u0026#39;ping 1.1.1.1 \u0026gt; /mon_dossier/ping.txt\u0026#39; Allons chercher l\u0026rsquo;emplacement du volume:\n$ docker inspect -f \u0026#39;{{ json .Mounts }}\u0026#39; c3 | jq Nous avons quasiment la même sortie qu\u0026rsquo;avec le Dockefile, à l\u0026rsquo;exception des IDs\n[ { \u0026quot;Type\u0026quot;: \u0026quot;volume\u0026quot;, \u0026quot;Name\u0026quot;: \u0026quot;0534a1308b43b5bb7f4f728daeedea7e9962a65b47df4d37e01b2ef89510bd13\u0026quot;, \u0026quot;Source\u0026quot;: \u0026quot;/var/lib/docker/volumes/0534a1308b43b5bb7f4f728daeedea7e9962a65b47df4d37e01b2ef89510bd13/_data\u0026quot;, \u0026quot;Destination\u0026quot;: \u0026quot;/mon_dossier\u0026quot;, \u0026quot;Driver\u0026quot;: \u0026quot;local\u0026quot;, \u0026quot;Mode\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;RW\u0026quot;: true, \u0026quot;Propagation\u0026quot;: \u0026quot;\u0026quot; } ] Vérifions que le fichier existe bien dans le volume:\n$ tail -f /var/lib/docker/volumes/\u0026lt;VOLUME_ID\u0026gt;/_data/ping.txt 64 bytes from 1.1.1.1: seq=11 ttl=59 time=0.807 ms 64 bytes from 1.1.1.1: seq=12 ttl=59 time=0.875 ms 64 bytes from 1.1.1.1: seq=13 ttl=59 time=0.828 ms 64 bytes from 1.1.1.1: seq=14 ttl=59 time=1.101 ms 64 bytes from 1.1.1.1: seq=15 ttl=59 time=1.039 ms 64 bytes from 1.1.1.1: seq=16 ttl=59 time=0.804 ms [...] Le fichier ping.txt est rempli regulièrement par la commande de notre conteneur.\nSi on supprime le conteneur, le processus va arrêter de remplir le fichier mais il ne sera psa supprimé.\nUtiliser un volume nommé Nous allons utiliser la commande pour créer un volume nommé web.\n$ docker volume create --name web Si nous listons les volumes existant, il devrait y avoir notre volume web.\n$ docker volume ls L\u0026rsquo;output devrait ressembler à ça:\nDRIVER VOLUME NAME [...]] local web Pour les volumes, comme presque tous les objets dans Docker, on peut executer la commande inpect.\n$ docker volume inspect web [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2020-06-14T14:27:06Z\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: {}, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/web/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;web\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] Le Mountpoint défini ici est le chemin sur l\u0026rsquo;hôte ou l\u0026rsquo;on peut trouver le volume.\nOn peut voir que le chemin des volumes nommés utilisent le nom du volume au lieu de l\u0026rsquo;ID comme dans les exemples précédent.\nOn peut maintenant utliser ce volume et le monter dans un conteneur.\nNous allons utiliser nginx et monter le volume web dans le répertoire /usr/share/nginx/html du conteneur.\n/usr/share/nginx/html est le répertoire par defaut du serveur nginx. Il contient 2 fichiers : index.html et 50x.html\n $ docker run -d --name www -p 8080:80 -v web:/usr/share/nginx/html nginx Depuis l\u0026rsquo;hôte, allons voir le contenu du volume.\n$ ls /var/lib/docker/volumes/web/_data 50x.html index.html Le contenu du dossier /usr/share/nginx/html du conteneur www à été copié dans le dossier /var/lib/docker/volumes/html/_data sur l\u0026rsquo;hôte.\nAllons vérifier la page d\u0026rsquo;accueil de nginx\n$ curl 127.0.0.1:8080 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Depuis l\u0026rsquo;hôte, nous pouvons désormais modifier le fichier index.html et vérifier que nos changements sont bien pris en compte par le conteneur.\n$ cat\u0026lt;\u0026lt;END \u0026gt;/var/lib/docker/volumes/web/_data/index.html TOC TOC TOC ! END Allons voir de nouveau la page web\n$ curl 127.0.0.1:8080 TOC TOC TOC ! Nous pouvons voir les changement que nous avons effectué.\nMonter un dossier de la VM dans un conteneur. The last item we will talk about is named bind-mount and consist of mounting a host\u0026rsquo;s folder into a container\u0026rsquo;s folder. This is done using the -v option of the docker container run command. Instead of specifying one single path (as we did when defining volumes) we will specified 2 paths separated by a column.\nNous allons maintenant monter un dossier de l\u0026rsquo;hôte dans un conteneur en faisant un bind-mount avec l\u0026rsquo;option -v : -v CHEMIN_HOTE:CHEMIN_CONTENEUR\nCHEMIN_HOTE et CHEMIN_CONTENEUR peuvent être un dossier ou un fichier.\nLe chemin sur l\u0026rsquo;hôte doit exister.\n Il y a deux cas bien distinct:\n le CHEMIN_CONTENEUR n\u0026rsquo;existe pas dans le conteneur. le CHEMIN_CONTENEUR existe dans le conteneur.  N\u0026rsquo;existe pas Executer un conteneur alpine en montant le /tmp local dans le dossier /mon_dossier du conteneur.\n$ docker run -ti -v /tmp:/mon_dossier alpine sh On arrive dans le shell de notre conteneur. Par défaut, il n\u0026rsquo;a pas de répertoire /mon_dossier dans l\u0026rsquo;image alpine.\nQuel est l\u0026rsquo;impact de notre bind mount ?\n$ ls /mon_dossier The /mon_dossier folder has been created inside the container and it contains the content of the /tmp folder of the host. We can now, from the container, change files on the host and the other way round.\nLe répertoire /mon_dossier à été créé dans le conteneur et contient les fichiers de /tmp de la VM.\nNous pouvons maintenant modifier ces fichiers à partir du conteneur ou de l\u0026rsquo;hôte.\nExiste Executer un conteneur nginx en montant le /tmp local dans le dossier /usr/share/nginx/html du conteneur.\n$ docker run -ti -v /tmp:/usr/share/nginx/html nginx bash Est ce que les fichiers par défaut index.html et 50x.html sont présent dans le dossier /usr/share/nginx/html du conteneur ?\n$ ls /usr/share/nginx/html Non.\nLe contenu du dossier du conteneur à été à été remplacé avec le contenu du dossier de l\u0026rsquo;hôte.\nLes bind-mount sont utiles en mode dévelopement car il permettent, par exemple, de partager le code source de l\u0026rsquo;hôte avec le conteneur.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/automatisation_image/","title":"Automatisation d&#39;une image","tags":[],"description":"","content":"Chapter 3 L\u0026rsquo;automatisation de la création d\u0026rsquo;une image Dans ce chapître, nous allons utiliser les Dockerfile, puis faire un tour d\u0026rsquo;horizon du DockerHub.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/docker/copy_on_write/","title":"Copy-On-Write","tags":[],"description":"","content":"Le copy-on-write Le copy-on-write ( CoW ) permet de partager les layers des images entre les conteneurs.\nDès que le conteneur à besoin d\u0026rsquo;ecrire dans un fichier existant dans une image, celui-ci est copié dans le layer en écriture du conteneur puis modifié.\nOn retrouve ce principe dans les snapshots BTRFS, le provisioning VMwawre,\u0026hellip;\nGrâce à cela, le demarrage des conteneurs est rapide, pas besoin de copier l\u0026rsquo;image.\nLe système de fichier CoW recommandé et supporté par docker est Overlay2\nL\u0026rsquo;avantage est qu\u0026rsquo;il est disponible sur tous les kernel linux recent.\nContainers that write a lot of data will consume more space than containers that do not. This is because most write operations consume new space in the container’s thin writable top layer. If your container needs to write a lot of data, you should consider using a data volume.\nLes conteneurs qui ecrivent beaucoup de données vont par contre consommer plus d\u0026rsquo;espace et seront plus lent, d\u0026rsquo;autant plus si le fichier à copier est gros. Dans ce cas la, l\u0026rsquo;utilisation d\u0026rsquo;un volume est recommandé.\nLes volumes seront abordés un peu plus tard dans les chapitres.\n Démo  Lancer 5 conteneurs avec l\u0026rsquo;image utilisé précédement zaggash/random Chercher les IDs des conteneurs fraîchement démarré.   Lancer un shell dans un conteneur puis ajouter un fichier dans /root Inspecter le conteneur avec docker inspect puis chercher dans le json:  [...] \u0026#34;GraphDriver\u0026#34;: { \u0026#34;Data\u0026#34;: { [...] \u0026#34;MergedDir\u0026#34;: \u0026#34;[...]\u0026#34;, ...  Verifier le contenu de ce dossier. Executer la commande mount sur la VM, qu\u0026rsquo;en concluez vous ?  "},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/installer_docker/","title":"Installer Docker","tags":[],"description":"","content":"Dans cette partie, nous allons prendre la main sur les VMs et installer Docker qui nous servira tout au long de la suite du TP.\nConnection à la VM Dans un premier temps, se connecter en SSH à la VM.\nAfin de preparer l\u0026rsquo;environement pour la suite, l\u0026rsquo;installation devra se faire sur les 3 VMs.\nssh [-i private_key] user@hostname Mettre à jour l\u0026rsquo;OS Afin d\u0026rsquo;être dans les meilleurs conditions possible et que nos machines soient identiques, commençons par mettre à jour les VMs.\n$ sudo apt-get update $ sudo apt-get upgrade -y $ sync \u0026amp;\u0026amp; sync \u0026amp;\u0026amp; sudo reboot Puis procéder à l\u0026rsquo;installation des paquets bridge-utils, jq et git qui nous serviront par la suite.\n$ sudo apt-get install -y bridge-utils jq git Installer Docker La procédure d\u0026rsquo;installation est bien detaillée sur le site de Docker.\nInstaller Docker sur Ubuntu TLDR:\n$ sudo apt-get install \\  apt-transport-https \\  ca-certificates \\  curl \\  gnupg-agent \\  software-properties-common $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - $ sudo apt-key fingerprint 0EBFCD88 $ sudo add-apt-repository \\  \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs)\\ stable\u0026#34; $ sudo apt-get update $ sudo apt-get install docker-ce docker-ce-cli containerd.io Verifier que le daemon est bien lancé\n$ sudo systemctl status docker docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2020-06-11 20:29:54 UTC; 9min ago Docs: https://docs.docker.com Main PID: 7807 (dockerd) Tasks: 30 [...] Lancer un premier conteneur L\u0026rsquo;accès à docker est considéré commen un accès root sur le serveur.\nC\u0026rsquo;est pourquoi l\u0026rsquo;utilisateur \u0026ldquo;docker\u0026rdquo; est quivalent à \u0026ldquo;root\u0026rdquo;.\n Pour simplifier l\u0026rsquo;execution des commandes et éviter de taper \u0026ldquo;sudo\u0026rdquo; devant chaque commandes, nous allons ajouter notre utilisateur au groupe \u0026ldquo;docker\u0026rdquo;.\n$ sudo usermod -G docker my_user [ relancer la connection ssh ]\n$ docker run --rm hello-world Hello from Docker! [...] Voilà vous avez executé un premier conteneur\u0026hellip;\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/architecture/namespaces_cgroups/","title":"Namespaces/Cgroups/CoW","tags":[],"description":"","content":"Docker est extremement lié au Kernel.\nLe fonctionnement des conteneurs reposent sur les namespaces, les cgroups et le CopyOnWrite.\nMais egalement d\u0026rsquo;autres aspects liés à la sécuritée comme les CAPabilities, seccomp,\u0026hellip;\nCeux qui nous interressent aujourd\u0026rsquo;hui sont les trois premiers : namespaces, cgroups et le CopyOnWrite.\nCes aspects seront abordés au cours des exercices du TP.\n Brièvement, les namespaces permettent l\u0026rsquo;isolation des processus à differant niveaux (PID, User, Network, Mount)\nLes Cgroups permettent l\u0026rsquo;isolation, la limitation de l\u0026rsquo;utilisation des ressources (Processeur, Memoire, Utilisation Disque)\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/pourquoi_docker/deploiement_simplifie/","title":"Deploiements simplifiés.","tags":[],"description":"","content":"Une application construite dans une image peut tourner n\u0026rsquo;importe où.\nCela simplifie la chaine de deploiement et assure que l\u0026rsquo;application soit la même partout où elle s\u0026rsquo;execute.\nUn conteneur retire les problematiques de dependences, de differances de paquets entre les OS, de configurations qui différent.\nOn oublie le fameux: \u0026ldquo;Moi, ca marche sur ma machine\u0026hellip;\u0026rdquo;\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/docker_linux/","title":"Docker et Linux","tags":[],"description":"","content":"Chapter 4 Docker et Linux Dans cette partie, nous allons voir comment Docker s\u0026rsquo;intègre avec linux au niveau réseau puis la gestion des volumes.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/pourquoi_docker/avant_docker/","title":"Avant Docker","tags":[],"description":"","content":"Les applications étaient principalement toutes installées sur des Machines Virtuelles.\nCertaine fois plusieurs applications partage la même VM avec ses propres librairies, dependances, fichiers de configurations\u0026hellip;\nLes installations se sont ensuite automatisées avec Ansible, Chef, Puppet,\u0026hellip; mais il est très facile de mofifier un fichier directement sur la machine sans changer le template.\nCe qui rend les environement certaine fois non fiable.\nLes Ops et Dev n\u0026rsquo;ont pas forcement une manière simple partager les applications.\nLes environements varient ce qui crée des lenteurs et des frictions entre Dev et Ops.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/orchestration/","title":"Orchestration","tags":[],"description":"","content":"Chapter 5 Orchestration Cette partie mets en oeuvre l\u0026rsquo;ensemble de la stack de Docker.\nNous allons utiliser docker-compose dans un premier temps. Puis mettre en oeuvre un cluster Swarm.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/pourquoi_docker/apres_docker/","title":"Après Docker","tags":[],"description":"","content":"Les applications sont désormais deployées seules dans une image avec les dependences et configurations.\nDev et Prod peuvent facilement echanger l\u0026rsquo;application et la deployer en Production.\nLes mises à jour ne neccessitent plus une reinstallation mais seulement un changement d\u0026rsquo;image.\nDe la même maniere, il est désormais très simple de revenir à une version précédente.\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/introduction/pourquoi_docker/vm_conteneur/","title":"Alors, VM ou Conteneur ?","tags":[],"description":"","content":"La plupart du temps, les conteneurs tourent dans des VMs.\nLes applications profitent des bénéfices de la contenerisation et la flexibilité des VMs.\nFaire tourner des conteneurs dans une machine complétement physique ajoute des problématiques de scalabilitée.\nIl n\u0026rsquo;y a pas de véritée, tout est une question de besoin !\n   VM Conteneur     Lourd, dans l\u0026rsquo;ordre du Giga Léger, dans l\u0026rsquo;ordre du Mega   Overhead the l\u0026rsquo;hyperviseur Performance native de l\u0026rsquo;hôte   Chaques VMs à son propre OS Les conteneurs partagent l\u0026rsquo;OS de l\u0026rsquo;hôte   Virtualisation Hardware Virtualisation de l\u0026rsquo;OS   Demmarage dans l\u0026rsquo;ordre de la minute Demmarage de l\u0026rsquo;ordre de la milliseconde   Isolation complète, donc plus sécrisée Isolation au niveau du processus, potentiellement moins sécurisée    "},{"uri":"https://zaggash.github.io/tp-iut-docker/","title":"Home","tags":[],"description":"","content":"Home Ceci est un TP afin de découvrir Docker, les conteneurs et l\u0026rsquo;orchestration de conteneur.\nJ\u0026rsquo;ai essayé de mettre le plus d\u0026rsquo;informations possible dans les chapitres.\nN\u0026rsquo;hésitez à m\u0026rsquo;interpeller si vous rencontrez un problème, une erreur, ou avez besoin de plus d\u0026rsquo;explication.\nLa documentation sur le site de Docker peux apporter une aide complémentaire.\nAfin de mener à bien le TP, vous avez à votre disposition 3 VMs.\nSeule une sera utile jusqu\u0026rsquo;à la partie concernant l\u0026rsquo;orchestration.\nCeci n\u0026rsquo;a pas pour but de tout expliquer sur les conteneurs, mais fait plutôt office d\u0026rsquo;introduction.\nAmusez-vous !\n"},{"uri":"https://zaggash.github.io/tp-iut-docker/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://zaggash.github.io/tp-iut-docker/tags/","title":"Tags","tags":[],"description":"","content":""}]